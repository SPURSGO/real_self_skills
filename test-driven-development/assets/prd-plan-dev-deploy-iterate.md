本文档按“端到端交付闭环”的视角，把 **TDD 从需求文档 → 开发 → 上线 → 迭代** 的最佳实践拆成可落地的步骤、产出物与工程化要点。

整体目标是：**把需求不确定性前移消化，把风险在自动化测试里“提前爆雷”，把迭代成本锁在可控范围内。**

实践需验证...

------

## 1. 需求文档阶段：把“需求”变成“可测试的契约”

### 1.1 需求拆解的核心产物：验收标准（Acceptance Criteria）

不要从“功能描述”直接跳实现，先把文档转成可验证的标准，推荐格式：

- **Given / When / Then（Gherkin）**
- **业务规则表（决策表 Decision Table）**
- **边界条件清单（Boundary List）**
- **非功能指标（性能、稳定性、兼容性、可观测性）**

示例（文字即可，不一定真用 BDD 框架）：

- Given 用户未登录
  When 访问 /profile
  Then 返回 401 且不返回任何用户字段

把每条验收标准标上优先级：

- P0：必须（上线门槛）
- P1：重要（可延后但必须进入计划）
- P2：体验/优化

### 1.2 “测试视角的需求评审”

评审点不是 UI 细节，而是这些“可测试性问题”：

- 输入域是什么？非法输入如何处理？
- 并发/幂等/重试是什么契约？
- 时序与一致性：最终一致还是强一致？
- 失败模式：超时、降级、兜底、告警？
- 兼容策略：对老版本/老数据如何兼容？

产出物建议：

- **AC 列表 + 决策表**
- **风险清单（含测试策略）**
- **埋点与观测需求（指标、日志、trace）**

------

## 2. 设计阶段：面向可测试性做架构切分

### 2.1 用“测试金字塔”反推模块边界

典型分层（从内到外）：

- **Domain / Core（纯逻辑）**：最适合单元测试（快、稳定、覆盖高）
- **Adapters / Gateways（IO边界）**：用 mock/stub/fake 隔离
- **Use Case / Service（编排）**：侧重交互与规则组合
- **API/UI（薄层）**：少量端到端测试覆盖关键路径

原则：**让 70%+ 逻辑落在可纯测的核心层**，外层主要做组装与协议转换。

### 2.2 设计约束（让 TDD 不痛）

- **依赖倒置**：核心逻辑只依赖接口，不依赖具体实现
- **时间/随机数/ID 生成可注入**：避免测试不稳定
- **IO 与纯逻辑隔离**：把复杂度留在可测试的地方
- **错误与状态建模清晰**：用明确的返回类型/错误码/异常策略

产出物：

- 模块边界图（可简单用 mermaid）
- 关键接口定义（尤其外部依赖：DB/HTTP/IPC/文件/系统API）
- 数据契约（请求/响应、版本字段、兼容策略）

------

## 3. 开发阶段：经典 TDD 循环如何嵌入团队工程流程

### 3.1 单个需求点的“微循环”：Red → Green → Refactor

每个 AC / 业务规则点建议都走一遍小循环：

1. **写失败测试（Red）**
   - 覆盖一个最小业务规则
   - 断言清晰（输入、输出、错误、状态变化）
2. **写最少实现通过（Green）**
   - 允许“丑”但不能破坏边界设计
   - 优先实现最小路径
3. **重构（Refactor）**
   - 消除重复、提炼函数/类、引入策略/表驱动
   - 重构过程中测试必须一直绿

### 3.2 “测试组合拳”：单测 + 组件测试 + 契约测试 + E2E

建议配比（经验值，非死规矩）：

- 单元测试：覆盖业务规则、边界条件（最多）
- 组件/集成测试：验证模块与真实依赖的集成（少量但关键）
- 契约测试（Contract Test）：你依赖别人的接口/别人依赖你的接口时非常关键
- 端到端测试：只保留关键用户路径（数量要克制）

### 3.3 Mock / Stub / Fake 的使用策略（减少脆弱测试）

- **优先 fake**（内存版仓库、内存队列）来提升稳定性与可维护性
- **mock 只用于验证交互契约**（例如必须调用一次、必须带某参数）
- **stub 用于固定返回**（例如外部服务返回某配置）

核心目标：减少“随实现细节变化就碎”的测试。

### 3.4 PR / Code Review 的硬门槛（强烈建议固化）

- 新增/修改逻辑必须有对应测试：覆盖新增规则和边界
- 变更必须更新 AC 对应测试或说明为何不需要
- 代码结构检查点：是否引入不可测耦合（静态单例、全局状态、直接 new 外部依赖等）
- 测试质量检查点：命名、断言信息量、是否存在随机/时间不稳定

------

## 4. CI/CD 阶段：把“上线信心”变成流水线产物

### 4.1 分层流水线（速度与可靠性的平衡）

推荐流水线分层：

1. **Lint / Format / Static Analysis**（最快）
2. **Unit Tests**（快、全量、并行）
3. **Component/Integration Tests**（可并行、可分组）
4. **Contract Tests**（对外依赖与对内提供）
5. **E2E Smoke**（只跑关键路径）
6. **性能/稳定性抽样**（按需，夜间或合并到主干前）

### 4.2 Gate 机制：什么可以阻断发布

- 单测/关键集成测试失败：阻断
- 覆盖率下降到阈值以下：阻断（阈值要合理，避免形式主义）
- 关键安全/合规扫描失败：阻断
- 关键指标回归（可通过基准测试或对比历史）：阻断或需要人工批准

------

## 5. 上线阶段：TDD 的闭环不是“测试全绿就完事”

上线需要把“不确定性”继续收敛：

### 5.1 发布策略

- 灰度/金丝雀
- Feature Flag（强烈建议：便于回滚、A/B、逐步开放）
- 兼容性：新旧版本共存、数据迁移策略（双写/回填/版本字段）

### 5.2 可观测性与“线上验收”

把 AC 的关键点映射为线上可观察指标：

- 成功率、错误码分布、延迟分位数
- 关键链路 trace
- 业务指标（转化、留存等看业务类型）

上线检查表：

- 日志能定位问题（结构化字段齐全）
- 告警阈值与抑制策略合理（避免噪音）
- 回滚路径明确且演练过（至少在测试环境演练）

------

## 6. 迭代阶段：把线上反馈变成下一轮 TDD 输入

### 6.1 缺陷处理的标准闭环（非常关键）

当线上出现 bug：

1. **先写回归测试复现（Red）**
2. 修复让测试变绿（Green）
3. 重构与补充边界用例（Refactor）
4. 把该 bug 归因到“需求缺失/设计缺失/测试缺失/观测缺失”中的一类
5. 更新相应清单/模板（让同类问题以后更难发生）

这是 TDD 体系提升“净收益”的核心点：**每次事故都沉淀为自动化护城河。**

### 6.2 版本演进中的测试资产治理

- 删除重复或价值低的 E2E（保留关键路径）
- 单测保持规则覆盖：业务规则变更必须同步更新
- 对 flaky test 零容忍：发现就治理（隔离时间、随机、并发、环境依赖）
- 逐步把过多 mock 的测试替换为 fake 或更高层的契约测试

------

## 7. 一个可直接复用的“端到端清单”

### 7.1 需求进入开发前

- AC/决策表齐全
- 失败模式定义（超时、重试、幂等、降级）
- 兼容策略、数据迁移策略明确
- 可观测性需求明确

### 7.2 开发中

- 规则先测试
- 依赖可注入
- 核心逻辑无 IO
- mock 限制在交互契约上

### 7.3 合并与发布

- 分层 CI 全绿
- 关键路径 smoke 通过
- 灰度与回滚方案具备
- 指标与告警到位

### 7.4 迭代

- 线上 bug 必须先加回归测试
- flaky test 治理
- 测试金字塔长期保持健康比例



## 一句话流程

需求→AC→测试用例→实现→迭代需求(形成闭环)

